import requests
import json
import cv2
import numpy as np
import matplotlib.pyplot as plt
import random
from collections import defaultdict
from sklearn.cluster import MeanShift, estimate_bandwidth

prediction_endpoint = "https://chillchill-prediction.cognitiveservices.azure.com"
prediction_key = "51U32IRMi4rdmNqwvaX4IFoKpHS6gJTReP4YtA1Riwz5HwMbt1bMJQQJ99BBACHYHv6XJ3w3AAAIACOGpfOe"
project_id = "9dcf7743-0e90-409f-beeb-35da8ae023aa"
model_name = "Iteration8"

## Custom Vision ê²°ê³¼ í™•ì¸
# ì„ê³„ê°’ ì„¤ì •
THRESHOLD = 0.8  # 80% ì´ìƒ í™•ë¥ ë§Œ í‘œì‹œ

#ì´ë¯¸ì§€ ê²½ë¡œ
image_file = f"data/musinsa_images_pants_ver2/pants_313.jpg"

# ì¹´í…Œê³ ë¦¬ë³„ ìƒ‰ìƒ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
category_colors = defaultdict(lambda: (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)))

def detect_objects(image_path):
    # ì´ë¯¸ì§€ ë¡œë“œ
    with open(image_path, "rb") as image_file:
        image_data = image_file.read()

    # API ìš”ì²­ í—¤ë” ë° ë°ì´í„°
    headers = {
        "Prediction-Key": prediction_key,
        "Content-Type": "application/octet-stream"
    }
    url = f"{prediction_endpoint}/customvision/v3.0/Prediction/{project_id}/detect/iterations/{model_name}/image"
    
    # ìš”ì²­ ì „ì†¡
    response = requests.post(url, headers=headers, data=image_data)
    
    if response.status_code != 200:
        print("Error:", response.text)
        return None

    # JSON ì‘ë‹µ ë°ì´í„° íŒŒì‹±
    return response.json()

def visualize_detections(image_path, detections):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    for prediction in detections["predictions"]:
        probability = prediction["probability"]
        if probability < THRESHOLD:
            continue  # ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ë¬´ì‹œ

        tag_name = prediction["tagName"]
        bbox = prediction["boundingBox"]

        # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ë³€í™˜
        h, w, _ = image.shape
        x1, y1 = int(bbox["left"] * w), int(bbox["top"] * h)
        x2, y2 = int((bbox["left"] + bbox["width"]) * w), int((bbox["top"] + bbox["height"]) * h)

        # ì¹´í…Œê³ ë¦¬ë³„ ìƒ‰ìƒ ì„ íƒ
        color = category_colors[tag_name]

        # ë°”ìš´ë”© ë°•ìŠ¤ ë° í…ìŠ¤íŠ¸ ì¶”ê°€
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        cv2.putText(image, f"{tag_name} ({probability:.2f})", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # # ê²°ê³¼ ì‹œê°í™”
    # plt.figure(figsize=(10, 8))
    # plt.imshow(image)
    # plt.axis("off")
    # plt.show()

# ì‹¤í–‰ ì˜ˆì‹œ

detections = detect_objects(image_file)
if detections:
     visualize_detections(image_file, detections)


## í•„ìš”í•œ ë¶€ë¶„ë§Œ ê°€ì ¸ì˜¤ê¸°
def show_cropped_objects_clean(image_path, detections, threshold=THRESHOLD):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    cropped_images = []  # í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    for prediction in detections["predictions"]:
        probability = prediction["probability"]
        if probability < threshold:
            continue  # ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ë¬´ì‹œ

        tag_name = prediction["tagName"]
        bbox = prediction["boundingBox"]

        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë³€í™˜
        h, w, _ = image.shape
        x1, y1 = int(bbox["left"] * w), int(bbox["top"] * h)
        x2, y2 = int((bbox["left"] + bbox["width"]) * w), int((bbox["top"] + bbox["height"]) * h)

        # ê°ì²´ ë¶€ë¶„ ì˜ë¼ë‚´ê¸°
        cropped_object = image[y1:y2, x1:x2]
        cropped_images.append((tag_name, probability, cropped_object))  # (ë¼ë²¨, í™•ë¥ , ì´ë¯¸ì§€) ì €ì¥

        # # ìƒˆ ì°½ì— ê°œë³„ ì´ë¯¸ì§€ ì¶œë ¥
        # plt.figure(figsize=(3, 3))
        # plt.imshow(cropped_object)
        # plt.title(f"{tag_name} ({probability:.2f})")
        # plt.axis("off")
        # plt.show()

    return cropped_images  # í¬ë¡­ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

# ì‹¤í–‰ ì˜ˆì‹œ
cropped_objects = show_cropped_objects_clean(image_file, detections)

# ë°˜í™˜ëœ ì´ë¯¸ì§€ í™•ì¸
# for tag, prob, img in cropped_objects:
#     print(f"Tag: {tag}, Probability: {prob:.2f}, Image Shape: {img.shape}")





def remove_background(cropped_images):
    final_images = []  # ìµœì¢… ê²°ê³¼ ì €ì¥

    for tag, prob, img in cropped_images:
        h, w, _ = img.shape
        
        # ì´ˆê¸° ë§ˆìŠ¤í¬ ì„¤ì •
        mask = np.zeros((h, w), np.uint8)
        bgd_model = np.zeros((1, 65), np.float64)
        fgd_model = np.zeros((1, 65), np.float64)
        
        # GrabCutì„ ìœ„í•œ ì´ˆê¸° ì‚¬ê°í˜• (ì¡°ê¸ˆ ì‘ê²Œ ì„¤ì •)
        rect = (5, 5, w-10, h-10)
        cv2.grabCut(img, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)
        
        # ë°°ê²½ê³¼ ì „ê²½ ë¶„ë¦¬
        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype("uint8")
        result = img * mask2[:, :, np.newaxis]
        
        # ê²½ê³„ ë¶€ë“œëŸ½ê²Œ (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©)
        blurred = cv2.GaussianBlur(result, (5, 5), 0)

        # ì•ŒíŒŒ ì±„ë„ ì¶”ê°€
        alpha = mask2 * 255
        rgba = np.dstack([blurred, alpha])

        # # ğŸ“Œ ìµœì¢… ì´ë¯¸ì§€ ì¶œë ¥
        # plt.figure(figsize=(4, 4))
        # plt.imshow(rgba)
        # plt.title(f"{tag} (Transparent Background)", fontsize=12)
        # plt.axis("off")
        # plt.show()

        final_images.append((tag, rgba))  # ê²°ê³¼ ì €ì¥
    
    return final_images  # ìµœì¢… ì´ë¯¸ì§€ ë°˜í™˜

# ğŸ”¥ ì‹¤í–‰
final_results = remove_background(cropped_objects)


def get_most_dominant_color(final_results, quantile=0.2, n_samples=1000):
    """
    ê° ì´ë¯¸ì§€ì—ì„œ ê°€ì¥ ë¹„ìœ¨ì´ ë†’ì€ ìƒ‰ìƒì˜ hex codeë§Œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Parameters:
    -----------
    final_results : list of tuples
        (tag, rgba_img) í˜•íƒœì˜ íŠœí”Œì„ ë‹´ì€ ë¦¬ìŠ¤íŠ¸
    quantile : float
        Mean-Shift í´ëŸ¬ìŠ¤í„°ë§ì˜ bandwidth ì¶”ì •ì— ì‚¬ìš©í•  quantile ê°’
    n_samples : int
        bandwidth ì¶”ì •ì— ì‚¬ìš©í•  ìƒ˜í”Œ ìˆ˜
    
    Returns:
    --------
    dict
        ì´ë¯¸ì§€ íƒœê·¸ë¥¼ í‚¤ë¡œ í•˜ê³ , (hex_code, percentage) íŠœí”Œì„ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    """
    dominant_colors = {}
    
    for tag, rgba_img in final_results:
        mask = rgba_img[:, :, 3] > 0
        pixels = rgba_img[mask][:, :3]
        
        if len(pixels) == 0:
            dominant_colors[tag] = None
            continue
            
        bandwidth = estimate_bandwidth(pixels, quantile=quantile, n_samples=n_samples)
        ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)
        
        labels = ms.fit_predict(pixels)
        cluster_centers = ms.cluster_centers_.astype(int)
        
        counts = np.bincount(labels)
        dominant_label = np.argmax(counts)
        dominant_color = cluster_centers[dominant_label]
        percentage = (counts[dominant_label] / len(pixels)) * 100
        
        hex_code = '#{:02x}{:02x}{:02x}'.format(
            dominant_color[0],
            dominant_color[1],
            dominant_color[2]
        )
        
        dominant_colors[tag] = (hex_code, percentage)
    
    return dominant_colors

for tag, prob, img in cropped_objects:
    print(f"Tag: {tag}, Probability: {prob:.2f}, Image Shape: {img.shape}")


# ì‹¤í–‰ ë°©ë²•
results = get_most_dominant_color(final_results)
for tag, color_info in results.items():
    if color_info:
        hex_code, percentage = color_info
        print(f"{tag}: {hex_code} ({percentage:.1f}%)")
    else:
        print(f"{tag}: No valid pixels found")
